{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = 'local'\n",
    "# ENV = 'kaggle'\n",
    "\n",
    "if ENV == 'local':\n",
    "    ROOT_DIR = './input/'\n",
    "elif ENV == 'kaggle':\n",
    "    ROOT_DIR = '/kaggle/inpupt/'\n",
    "else:\n",
    "    raise Exception('Unknown Environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing g:\\my drive\\kaggle\\commonlit\\input\\pyspellchecker\\pyspellchecker-0.7.2-py3-none-any.whl\n",
      "pyspellchecker is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "if ENV == 'local':\n",
    "    !pip install \"./input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"\n",
    "elif ENV == 'kaggle':\n",
    "    !pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"\n",
    "else:\n",
    "    raise Exception('Unknown Environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: transformers in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (4.33.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (4.33.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from transformers[torch]) (2.0.1)\n",
      "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "                                              0.0/258.1 kB ? eta -:--:--\n",
      "     -                                        10.2/258.1 kB ? eta -:--:--\n",
      "     ----------                            71.7/258.1 kB 787.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 258.1/258.1 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.23.0\n",
      "Requirement already satisfied: accelerate in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from accelerate) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "# logging setting \n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"debertav3base\"\n",
    "    learning_rate=1.5e-5\n",
    "    weight_decay=0.02\n",
    "    hidden_dropout_prob=0.007\n",
    "    attention_probs_dropout_prob=0.007\n",
    "    num_train_epochs=10\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ROOT_DIR + \"commonlit-evaluate-student-summaries/\"\n",
    "#DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "\n",
    "# summaries_train = summaries_train.head(10) # for dev mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "[Using features]\n",
    "- Text Length\n",
    "- Length Ratio\n",
    "- Word Overlap\n",
    "- N-grams Co-occurrence\n",
    "- Quotes Overlap\n",
    "    - Grammar Check\n",
    " spelling: pyspellchecker\n",
    "\n",
    "NOTE: I don't know why, but I can't use nltk.ngrams function. (my submission fails \"Submission CSV Not Found\") So, I write and use original ngram function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ROOT_DIR + model_name)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = SpellChecker() #Speller(lang='en')\n",
    "        \n",
    "    def count_text_length(self, df: pd.DataFrame, col:str) -> pd.Series:\n",
    "        \"\"\" text length \"\"\"\n",
    "        tokenizer=self.tokenizer\n",
    "        return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "    def word_overlap_count(self, row):\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "            \n",
    "    def ngrams(self, token, n):\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int):\n",
    "        # Tokenize the original text and summary into words\n",
    "        original_tokens = row['prompt_tokens']\n",
    "        summary_tokens = row['summary_tokens']\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
    "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "\n",
    "        # # Optionally, you can get the frequency of common n-grams for a more nuanced analysis\n",
    "        # original_ngram_freq = Counter(ngrams(original_words, n))\n",
    "        # summary_ngram_freq = Counter(ngrams(summary_words, n))\n",
    "        # common_ngram_freq = {ngram: min(original_ngram_freq[ngram], summary_ngram_freq[ngram]) for ngram in common_ngrams}\n",
    "\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str):\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text):\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.speller.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame:\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: len(self.tokenizer.encode(x))\n",
    "        )\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
    "            lambda x: len(self.tokenizer.encode(x))\n",
    "        )\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "\n",
    "        )\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "\n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        \n",
    "        # Crate dataframe with count of each category NERs overlap for all the summaries\n",
    "        # Because it spends too much time for this feature, I don't use this time.\n",
    "#         ners_count_df  = input_df.progress_apply(\n",
    "#             lambda row: pd.Series(self.ner_overlap_count(row, mode=mode), dtype='float64'), axis=1\n",
    "#         ).fillna(0)\n",
    "#         self.ner_keys = ners_count_df.columns\n",
    "#         ners_count_df['sum'] = ners_count_df.sum(axis=1)\n",
    "#         ners_count_df.columns = ['NER_' + col for col in ners_count_df.columns]\n",
    "#         # join ner count dataframe with train dataframe\n",
    "#         input_df = pd.concat([input_df, ners_count_df], axis=1)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [00:01<00:00, 3670.53it/s]\n",
      "100%|██████████| 7165/7165 [00:01<00:00, 5483.42it/s]\n",
      "100%|██████████| 7165/7165 [00:03<00:00, 1852.86it/s]\n",
      "100%|██████████| 7165/7165 [00:05<00:00, 1298.76it/s]\n",
      "100%|██████████| 7165/7165 [00:00<00:00, 41879.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4013.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3794.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4013.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4016.57it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2007.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>quotes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text  summary_length  splling_err_num  \\\n",
       "0  000000ffffff    abc123  Example text 1               5                0   \n",
       "1  111111eeeeee    def789  Example text 2               5                0   \n",
       "2  222222cccccc    abc123  Example text 3               5                0   \n",
       "3  333333dddddd    def789  Example text 4               5                0   \n",
       "\n",
       "  prompt_question     prompt_title       prompt_text  prompt_length  \\\n",
       "0    Summarize...  Example Title 1  Heading\\nText...              7   \n",
       "1    Summarize...  Example Title 2  Heading\\nText...              7   \n",
       "2    Summarize...  Example Title 1  Heading\\nText...              7   \n",
       "3    Summarize...  Example Title 2  Heading\\nText...              7   \n",
       "\n",
       "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
       "0      0.714286                   0                     0   \n",
       "1      0.714286                   0                     0   \n",
       "2      0.714286                   0                     0   \n",
       "3      0.714286                   0                     0   \n",
       "\n",
       "   trigram_overlap_count  quotes_count  \n",
       "0                      0             0  \n",
       "1                      0             0  \n",
       "2                      0             0  \n",
       "3                      0             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>quotes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1137</td>\n",
       "      <td>0.049252</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>285</td>\n",
       "      <td>32</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>651</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>651</td>\n",
       "      <td>0.066052</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>253</td>\n",
       "      <td>29</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  summary_length  splling_err_num  \\\n",
       "0  0.205683  0.380538              69                5   \n",
       "1 -0.548304  0.506755              56                2   \n",
       "2  3.128928  4.231226             285               32   \n",
       "3 -0.210614 -0.471415              43                5   \n",
       "4  3.272894  3.219757             253               29   \n",
       "\n",
       "                                     prompt_question  \\\n",
       "0  Summarize how the Third Wave developed over su...   \n",
       "1  Summarize the various ways the factory would u...   \n",
       "2  In complete sentences, summarize the structure...   \n",
       "3  In complete sentences, summarize the structure...   \n",
       "4  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0             The Third Wave   \n",
       "1    Excerpt from The Jungle   \n",
       "2  Egyptian Social Structure   \n",
       "3  Egyptian Social Structure   \n",
       "4             The Third Wave   \n",
       "\n",
       "                                         prompt_text  prompt_length  \\\n",
       "0  Background \\r\\nThe Third Wave experiment took ...            671   \n",
       "1  With one member trimming beef in a cannery, an...           1137   \n",
       "2  Egyptian society was structured like a pyramid...            651   \n",
       "3  Egyptian society was structured like a pyramid...            651   \n",
       "4  Background \\r\\nThe Third Wave experiment took ...            671   \n",
       "\n",
       "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
       "0      0.102832                   0                     5   \n",
       "1      0.049252                   0                    22   \n",
       "2      0.437788                   1                    56   \n",
       "3      0.066052                   1                    10   \n",
       "4      0.377049                   1                    27   \n",
       "\n",
       "   trigram_overlap_count  quotes_count  \n",
       "0                      0             0  \n",
       "1                     10             0  \n",
       "2                     26             2  \n",
       "3                      6             0  \n",
       "4                      5             4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>quotes_count</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1137</td>\n",
       "      <td>0.049252</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>285</td>\n",
       "      <td>32</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>651</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>651</td>\n",
       "      <td>0.066052</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>253</td>\n",
       "      <td>29</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  summary_length  splling_err_num  \\\n",
       "0  0.205683  0.380538              69                5   \n",
       "1 -0.548304  0.506755              56                2   \n",
       "2  3.128928  4.231226             285               32   \n",
       "3 -0.210614 -0.471415              43                5   \n",
       "4  3.272894  3.219757             253               29   \n",
       "\n",
       "                                     prompt_question  \\\n",
       "0  Summarize how the Third Wave developed over su...   \n",
       "1  Summarize the various ways the factory would u...   \n",
       "2  In complete sentences, summarize the structure...   \n",
       "3  In complete sentences, summarize the structure...   \n",
       "4  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0             The Third Wave   \n",
       "1    Excerpt from The Jungle   \n",
       "2  Egyptian Social Structure   \n",
       "3  Egyptian Social Structure   \n",
       "4             The Third Wave   \n",
       "\n",
       "                                         prompt_text  prompt_length  \\\n",
       "0  Background \\r\\nThe Third Wave experiment took ...            671   \n",
       "1  With one member trimming beef in a cannery, an...           1137   \n",
       "2  Egyptian society was structured like a pyramid...            651   \n",
       "3  Egyptian society was structured like a pyramid...            651   \n",
       "4  Background \\r\\nThe Third Wave experiment took ...            671   \n",
       "\n",
       "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
       "0      0.102832                   0                     5   \n",
       "1      0.049252                   0                    22   \n",
       "2      0.437788                   1                    56   \n",
       "3      0.066052                   1                    10   \n",
       "4      0.377049                   1                    27   \n",
       "\n",
       "   trigram_overlap_count  quotes_count  fold  \n",
       "0                      0             0   3.0  \n",
       "1                     10             0   2.0  \n",
       "2                     26             2   1.0  \n",
       "3                      6             0   1.0  \n",
       "4                      5             4   3.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                inputs: List[str],\n",
    "                target_cols: List[str],\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        \n",
    "        self.input_col = \"input\" # col name of model input after text concat sep token\n",
    "        \n",
    "        self.input_text_cols = inputs\n",
    "        self.target_cols = target_cols\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ROOT_DIR + model_name)\n",
    "        self.model_config = AutoConfig.from_pretrained(ROOT_DIR + model_name)\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        #self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 2,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "    def concatenate_with_sep_token(self, row):\n",
    "        sep = \" \" + self.tokenizer.sep_token + \" \"        \n",
    "        return sep.join(row[self.input_text_cols])\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[\"content\"], examples[\"wording\"]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                        padding=\"max_length\",\n",
    "                        truncation=True,\n",
    "                        max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                        padding=\"max_length\",\n",
    "                        truncation=True,\n",
    "                        max_length=self.max_length)\n",
    "        return tokenized\n",
    "        \n",
    "    def train(self, \n",
    "            fold: int,\n",
    "            train_df: pd.DataFrame,\n",
    "            valid_df: pd.DataFrame,\n",
    "            batch_size: int,\n",
    "            learning_rate: float,\n",
    "            weight_decay: float,\n",
    "            num_train_epochs: float,\n",
    "            save_steps: int,\n",
    "        ) -> None:\n",
    "        \"\"\"fine-tuning\"\"\"\n",
    "                \n",
    "        train_df[self.input_col] = train_df.apply(self.concatenate_with_sep_token, axis=1)\n",
    "        valid_df[self.input_col] = valid_df.apply(self.concatenate_with_sep_token, axis=1)        \n",
    "\n",
    "        train_df = train_df[[self.input_col] + self.target_cols]\n",
    "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            #f\"/kaggle/input/{self.model_name}\", \n",
    "            ROOT_DIR + self.model_name,\n",
    "            config=self.model_config\n",
    "        )\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False) \n",
    "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False) \n",
    "    \n",
    "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
    "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
    "\n",
    "        # eg. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            load_best_model_at_end=True, # select best model\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size, \n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            report_to='none',\n",
    "            greater_is_better=False,\n",
    "            save_strategy=\"steps\",\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=save_steps,\n",
    "            save_steps=save_steps,\n",
    "            metric_for_best_model=\"mcrmse\",\n",
    "            save_total_limit=1,\n",
    "            fp16=True,\n",
    "            auto_find_batch_size=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized_datasets,\n",
    "            eval_dataset=val_tokenized_datasets,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=compute_mcrmse,\n",
    "            data_collator=self.data_collator\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        model.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "        model.cpu()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                batch_size: int,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        test_df[self.input_col] = test_df.apply(self.concatenate_with_sep_token, axis=1)\n",
    "\n",
    "        test_dataset = Dataset.from_pandas(test_df[[self.input_col]], preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train=False,\n",
    "            do_predict=True,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            dataloader_drop_last=False,\n",
    "            fp16=True,\n",
    "            auto_find_batch_size=True,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "        pred_df = pd.DataFrame(\n",
    "            preds, \n",
    "            columns=[\n",
    "                f\"content_pred\", \n",
    "                f\"wording_pred\"\n",
    "           ]\n",
    "        )\n",
    "        \n",
    "        model.cpu()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_fold(\n",
    "        train_df: pd.DataFrame,\n",
    "        model_name: str,\n",
    "        targets: List[str],\n",
    "        inputs: List[str],\n",
    "        save_each_model: bool,\n",
    "        n_splits: int,\n",
    "        batch_size: int,\n",
    "        learning_rate: int,\n",
    "        hidden_dropout_prob: float,\n",
    "        attention_probs_dropout_prob: float,\n",
    "        weight_decay: float,\n",
    "        num_train_epochs: int,\n",
    "        save_steps: int,\n",
    "        max_length:int\n",
    "    ):\n",
    "\n",
    "    # delete old model files\n",
    "    if os.path.exists(model_name):\n",
    "        shutil.rmtree(model_name)\n",
    "    \n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        train_data = train_df[train_df[\"fold\"] != fold]\n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target_cols=targets,\n",
    "            inputs= inputs,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        csr.train(\n",
    "            fold=fold,\n",
    "            train_df=train_data,\n",
    "            valid_df=valid_data, \n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    mode: str,\n",
    "    targets: List[str],\n",
    "    inputs: List[str],\n",
    "    save_each_model: bool,\n",
    "    n_splits: int,\n",
    "    batch_size: int,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"predict oof data\"\"\"\n",
    "    \n",
    "    columns = list(train_df.columns.values)\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "        \n",
    "        csr = ScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target_cols=targets,\n",
    "            inputs= inputs,\n",
    "            model_dir = model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred_df = csr.predict(\n",
    "            test_df=valid_data, \n",
    "            batch_size=batch_size,\n",
    "            fold=fold\n",
    "        )\n",
    "\n",
    "        train_df.loc[valid_data.index, f\"content_{mode}_pred\"] = pred_df[f\"content_pred\"].values\n",
    "        train_df.loc[valid_data.index, f\"wording_{mode}_pred\"] = pred_df[f\"wording_pred\"].values\n",
    "                \n",
    "    return train_df[columns + [f\"content_{mode}_pred\", f\"wording_{mode}_pred\"]]\n",
    "    \n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    mode: str,\n",
    "    targets:List[str],\n",
    "    inputs: List[str],\n",
    "    save_each_model: bool,\n",
    "    n_splits: int,\n",
    "    batch_size: int,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "    \n",
    "    columns = list(test_df.columns.values)\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target_cols=targets,\n",
    "            inputs= inputs,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred_df = csr.predict(\n",
    "            test_df=test_df, \n",
    "            batch_size=batch_size,\n",
    "            fold=fold\n",
    "        )\n",
    "\n",
    "        test_df[f\"content_{mode}_pred_{fold}\"] = pred_df[f\"content_pred\"].values\n",
    "        test_df[f\"wording_{mode}_pred_{fold}\"] = pred_df[f\"wording_pred\"].values\n",
    "\n",
    "    test_df[f\"content_{mode}_pred\"] = test_df[[f\"content_{mode}_pred_{fold}\" for fold in range(n_splits)]].mean(axis=1)\n",
    "    test_df[f\"wording_{mode}_pred\"] = test_df[[f\"wording_{mode}_pred_{fold}\" for fold in range(n_splits)]].mean(axis=1)\n",
    "    \n",
    "    return test_df[columns + [f\"content_{mode}_pred\", f\"wording_{mode}_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\CommonLit\\debertav3_LGBM.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m input_cols \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mprompt_title\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt_question\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_cfg \u001b[39m=\u001b[39m CFG\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_by_fold(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     save_each_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     targets\u001b[39m=\u001b[39;49mtargets,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     inputs\u001b[39m=\u001b[39;49minput_cols,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     hidden_dropout_prob\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mhidden_dropout_prob,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     attention_probs_dropout_prob\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mattention_probs_dropout_prob,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mweight_decay,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mnum_train_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     n_splits\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mn_splits,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     save_steps\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49msave_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmodel_cfg\u001b[39m.\u001b[39;49mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m train \u001b[39m=\u001b[39m validate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     max_length\u001b[39m=\u001b[39mmodel_cfg\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# set validate result\u001b[39;00m\n",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\CommonLit\\debertav3_LGBM.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model_dir \u001b[39m=\u001b[39m  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/fold_\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m csr \u001b[39m=\u001b[39m ScoreRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     target_cols\u001b[39m=\u001b[39mtargets,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m    )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m csr\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     fold\u001b[39m=\u001b[39;49mfold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     train_df\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     valid_df\u001b[39m=\u001b[39;49mvalid_data, \n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     save_steps\u001b[39m=\u001b[39;49msave_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m )\n",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\CommonLit\\debertav3_LGBM.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m# eg. \"bert/fold_0/\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m model_fold_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_dir, \u001b[39mstr\u001b[39m(fold)) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49mmodel_fold_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     load_best_model_at_end\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# select best model\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     report_to\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     greater_is_better\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     save_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39;49msave_steps,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     save_steps\u001b[39m=\u001b[39;49msave_steps,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     metric_for_best_model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmcrmse\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     save_total_limit\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     fp16\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     auto_find_batch_size\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     data_collator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_collator\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/CommonLit/debertav3_LGBM.ipynb#X23sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32m<string>:114\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages\\transformers\\training_args.py:1405\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m==\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m   1400\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1402\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1405\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1406\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1407\u001b[0m     \u001b[39mand\u001b[39;00m (get_xla_device_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1408\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1409\u001b[0m ):\n\u001b[0;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1413\u001b[0m     )\n\u001b[0;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1416\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1423\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages\\transformers\\training_args.py:1852\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m \u001b[39mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1850\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m requires_backends(\u001b[39mself\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1852\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_devices\n",
      "File \u001b[1;32mc:\\Users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, attr, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[0;32m     55\u001b[0m     \u001b[39msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\keiko\\anaconda3\\envs\\kaggle_base\\lib\\site-packages\\transformers\\training_args.py:1767\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available(min_version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0.20.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     AcceleratorState\u001b[39m.\u001b[39m_reset_state(reset_partial_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1771\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "targets = [\"wording\", \"content\"]\n",
    "mode = \"multi\"\n",
    "input_cols = [\"prompt_title\", \"prompt_question\", \"text\"]\n",
    "model_cfg = CFG\n",
    "\n",
    "train_by_fold(\n",
    "    train,\n",
    "    model_name=model_cfg.model_name,\n",
    "    save_each_model=False,\n",
    "    targets=targets,\n",
    "    inputs=input_cols,\n",
    "    learning_rate=model_cfg.learning_rate,\n",
    "    hidden_dropout_prob=model_cfg.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=model_cfg.attention_probs_dropout_prob,\n",
    "    weight_decay=model_cfg.weight_decay,\n",
    "    num_train_epochs=model_cfg.num_train_epochs,\n",
    "    n_splits=CFG.n_splits,\n",
    "    batch_size=model_cfg.batch_size,\n",
    "    save_steps=model_cfg.save_steps,\n",
    "    max_length=model_cfg.max_length\n",
    ")\n",
    "\n",
    "\n",
    "train = validate(\n",
    "    train,\n",
    "    mode=mode,\n",
    "    targets=targets,\n",
    "    inputs=input_cols,\n",
    "    save_each_model=False,\n",
    "    n_splits=CFG.n_splits,\n",
    "    batch_size=model_cfg.batch_size,\n",
    "    model_name=model_cfg.model_name,\n",
    "    hidden_dropout_prob=model_cfg.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=model_cfg.attention_probs_dropout_prob,\n",
    "    max_length=model_cfg.max_length\n",
    ")\n",
    "\n",
    "# set validate result\n",
    "for target in [\"content\", \"wording\"]:\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_{mode}_pred\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "\n",
    "test = predict(\n",
    "    test,\n",
    "    mode=mode,\n",
    "    targets=targets,\n",
    "    inputs=input_cols,\n",
    "    save_each_model=False,\n",
    "    batch_size=model_cfg.batch_size,\n",
    "    n_splits=CFG.n_splits,\n",
    "    model_name=model_cfg.model_name,\n",
    "    hidden_dropout_prob=model_cfg.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=model_cfg.attention_probs_dropout_prob,\n",
    "    max_length=model_cfg.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ] + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = []\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "\n",
    "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
    "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
    "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
    "\n",
    "        params = {\n",
    "                  'boosting_type': 'gbdt',\n",
    "                  'random_state': 42,\n",
    "                  'objective': 'regression',\n",
    "                  'metric': 'rmse',\n",
    "                  'learning_rate': 0.05,\n",
    "                  }\n",
    "\n",
    "        evaluation_results = {}\n",
    "        model = lgb.train(params,\n",
    "                          num_boost_round=10000,\n",
    "                            #categorical_feature = categorical_features,\n",
    "                          valid_names=['train', 'valid'],\n",
    "                          train_set=dtrain,\n",
    "                          valid_sets=dval,\n",
    "                          callbacks=[\n",
    "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
    "                               lgb.log_evaluation(100),\n",
    "                              lgb.callback.record_evaluation(evaluation_results)\n",
    "                            ],\n",
    "                          )\n",
    "        models.append(model)\n",
    "    \n",
    "    model_dict[target] = models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv\n",
    "rmses = []\n",
    "\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        # ilocで取り出す行を指定\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "\n",
    "        trues.extend(y_eval_cv)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "                #\"fold\", \n",
    "                \"student_id\", \"prompt_id\", \"text\", \n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "    preds = []\n",
    "\n",
    "    for fold, model in enumerate(models):\n",
    "        # ilocで取り出す行を指定\n",
    "        X_eval_cv = test.drop(columns=drop_columns)\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    pred_dict[target] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    preds = pred_dict[target]\n",
    "    for i, pred in enumerate(preds):\n",
    "        test[f\"{target}_pred_{i}\"] = pred\n",
    "\n",
    "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
